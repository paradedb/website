import learnMetadata from "./metadata.json";
import { AuthorSection } from "@/components/AuthorSection";
import { Title } from "@/components/Title";
import { Note } from "@mintlify/components";
import Image from "next/image";

<Title metadata={learnMetadata} />
<AuthorSection metadata={learnMetadata} />

[Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25) is a **ranking function** used in search engines to score documents by relevance to a query. The BM is short for `best matching`, and `25` is the version of the function that worked best in testing. It improves on earlier methods like [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) by accounting for document length and diminishing returns from repeated terms. It powers Apache Lucene-based search systems like [Elasticsearch](https://github.com/elastic/elasticsearch) and [Solr](https://github.com/apache/solr), and Tantivy-based search systems like [ParadeDB](https://github.com/paradedb/paradedb).

Even though it's over 30 years old, BM25 remains the default ranking algorithm in most search engines because it’s simple, explainable, and performs well in practice.

## How BM25 Works

It's important to note that BM25 is what’s known as a [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) retrieval function. It doesn’t look at term order, phrase structure, or proximity: only at which words appear and how frequently they occur.

BM25 starts by breaking the search query into individual terms. For each term, it scores how well every document matches based on three main signals:

- **Term frequency (TF):** documents that mention a query term more often score higher.
- **Inverse document frequency (IDF):** rare terms are weighted more than common ones.
- **Document length normalization:** shorter documents are preferred to long ones that mention the term in passing.

Each term contributes its own score, and BM25 sums those scores to produce an overall relevance value for the document.

In simplified form, BM25 can be thought of as:

$$
\text{score} = \sum \text{IDF} \times \text{adjusted\_term\_frequency}
$$

where the adjusted term frequency reduces the impact of very frequent terms and normalizes for document length.

<Note>
  The full [BM25
  formula](https://en.wikipedia.org/wiki/Okapi_BM25#The_ranking_function) is
  slightly more complex. It includes tunable parameters $k₁$ (how quickly term
  frequency saturates) and $b$ (how strongly document length is normalized).
  These controls make BM25 adaptable across different datasets and document
  types.
</Note>

## Why BM25 Works Well

BM25 has three key strengths which have allowed it to stay relevant for so long:

- **Simplicity:** easy to understand and implement.
- **Efficiency:** fast enough to run in real-time over large datasets.
- **Explainability:** each part of the score can be traced to a clear factor.

Because of these traits, BM25 remains the baseline for relevance in modern search systems.

## When to Use BM25

BM25 excels in keyword-based retrieval workloads, where users search using exact terms or short phrases rather than natural language. It’s ideal when you want to find ranked documents that contain the same words a user types.

Think of use cases like:

- Searching for a brand name in a product catalog
- Looking up a stock ticker in a trading app
- Matching a merchant name in a credit card transaction ledger
- Finding names in a legal document
- Finding a diagnosis code in a medical report

Because BM25 relies on simple term statistics (how often a word appears and how common it is across documents) it’s accurate, consistent and extremely fast. That makes it a popular choice in applications where low query latency is critical, and where semantic meaning isn’t as important as exact keyword relevance.

## Example: Scoring a Query with BM25

Imagine a user searches for **"inverted index"**.

BM25 first breaks the query into two terms: **“inverted”** and **“index.”**

Then, for each document, it scores how well those terms match:

| **Document** | **Length** | **Term counts**            | **TF–IDF signals**                                          | **Relative Score** |
| ------------ | ---------- | -------------------------- | ----------------------------------------------------------- | ------------------ |
| **Doc A**    | 60 words   | inverted: 1<br />index: 1  | rare → high IDF<br />common → low IDF                       | **Higher**         |
| **Doc B**    | 200 words  | inverted: 1<br />index: 10 | rare → high IDF<br />common → low IDF<br />+ length penalty | **Lower**          |

Even though _Doc B_ repeats “index” more times, BM25 favors _Doc A_ because:

1. “inverted” is a rare term with higher IDF,
2. both documents mention it once (similar TF), and
3. _Doc A_ is shorter, so its matches are more concentrated.

**BM25 rewards focused, relevant mentions of rare terms, not repetition in long text.**

## Summary

BM25 remains the standard ranking algorithm for keyword search.

It combines frequency, rarity, and length normalization into a single scoring model that quickly produces balanced and predictable results.

For most full-text search applications BM25 is the right place to start.
