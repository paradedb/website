import Image from "next/image";
import blogMetadata from "./metadata.json";
import { AuthorSection } from "@/components/AuthorSection";
import { HeroImage } from "@/components/HeroImage";
import { Title } from "@/components/Title";
import heroImage from "./images/hero.png";

<Title metadata={blogMetadata} />
<AuthorSection metadata={blogMetadata} />
<HeroImage src={heroImage} metadata={blogMetadata} />

When Sarah first tried to add search to her e-commerce platform, she thought it would be straightforward. "Just index the product descriptions," she figured. Six months later, she was managing a complex pipeline between PostgreSQL, Elasticsearch, and a custom synchronization service that broke every other week. The search worked, but maintaining it felt like a full-time job.

Sound familiar? If you've ever built search functionality, you've probably lived this story. You start with simple requirements, then discover you need relevance tuning, then filtering, then analytics, then... suddenly you're an accidental search infrastructure expert.

ParadeDB's v2 API changes this narrative entirely. Instead of bolting search onto your database, it makes search feel like it was always part of PostgreSQL. Let's walk through building that same e-commerce search — but this time, we'll do it the v2 way.

## Starting Simple: Your First Search Index

Let's say we have a typical products table:

```sql
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    name TEXT,
    description TEXT,
    category TEXT,
    price DECIMAL(10,2),
    rating DECIMAL(2,1),
    created_at TIMESTAMP DEFAULT NOW()
);
```

In the old world, you'd export this data to Elasticsearch, define a mapping, set up a sync pipeline, and hope nothing breaks. With ParadeDB's v2 API, you simply create an index:

```sql
CREATE INDEX products_search ON products
USING bm25 (id, name, description, category, price, rating, created_at)
WITH (key_field='id');
```

That's it. ParadeDB looks at your table schema and makes intelligent decisions: text columns get tokenized for search, numeric columns become filterable, timestamps work for date ranges. No configuration files, no mapping definitions, no external services.

But here's where it gets interesting. Let's see how this data actually gets tokenized:

```sql
SELECT 'Wireless noise-cancelling headphones'::pdb.simple::text[];
-- Result: {wireless,noise,cancelling,headphones}
```

The v2 API lets you test tokenization directly in SQL. Want to see what n-grams look like?

```sql
SELECT 'iPhone'::pdb.ngram(3,3)::text[];
-- Result: {iph,pho,hon,one}
```

This transparency is crucial. You can understand exactly how your text will be searchable before you commit to an index.

## The Real World: Multiple Ways to Search the Same Data

Real applications need flexibility. Users might search for exact product codes, browse by category, or hunt for partial matches. Sarah's customers did all three.

Here's where v2's multi-tokenizer approach shines:

```sql
CREATE INDEX products_search ON products
USING bm25 (
    id,
    (name::pdb.literal),                        -- Exact matching for sorting
    (name::pdb.simple('alias=name_search')),    -- Tokenized for search
    (description::pdb.ngram(3,3)),              -- Partial matching
    category, price, rating, created_at
) WITH (key_field='id');
```

Now we can search the same `name` field in different ways:

```sql
-- Fuzzy text search
SELECT name, description FROM products
WHERE name::pdb.alias('name_search') ||| 'wireless headphones';

-- Exact sorting (uses the literal tokenizer)
SELECT name FROM products 
WHERE name::pdb.alias('name_search') ||| 'headphones'
ORDER BY name
LIMIT 10;

-- Partial matching on description
SELECT name FROM products
WHERE description ||| 'phone';  -- Matches "iPhone", "smartphone", etc.
```

## Search That Actually Feels Like Search

Now we get to the fun part. v2's search operators make query intent crystal clear:

```sql
-- Match any word (OR behavior)
SELECT name FROM products WHERE description ||| 'wireless bluetooth';

-- Match all words (AND behavior) 
SELECT name FROM products WHERE description &&& 'wireless bluetooth headphones';

-- Exact phrase
SELECT name FROM products WHERE description @@@ pdb.phrase('noise cancelling');

-- Fuzzy for typos
SELECT name FROM products WHERE name @@@ pdb.fuzzy('aplle', 1);  -- Finds "apple"
```

But what about when users want "Apple" products but type "apple phone"? Proximity search handles this beautifully:

```sql
-- Find "apple" within 2 words of "phone"
SELECT name FROM products 
WHERE description @@@ ('apple' ## 2 ## 'phone');

-- Same thing but order matters: "apple" must come before "phone"  
SELECT name FROM products
WHERE description @@@ ('apple' ##> 2 ##> 'phone');
```

## When Users Get Creative

Real users don't just search for product names. They search for "red bluetooth under $50" or "5-star wireless earbuds from this month." This is where traditional search systems start requiring custom code.

v2 handles this naturally through PostgreSQL syntax:

```sql
-- Complex filtering with search
SELECT name, price, rating FROM products
WHERE description ||| 'wireless earbuds'
  AND price < 50
  AND rating >= 4.5
  AND created_at > '2024-01-01';

-- Range queries for numbers
SELECT name, price FROM products  
WHERE price @@@ pdb.int4_range('[50,200)');  -- $50-199

-- Smart highlighting shows users what matched
SELECT name, pdb.snippet(description) FROM products
WHERE description ||| 'wireless bluetooth'
LIMIT 5;
-- Result includes: "Compact <b>wireless</b> <b>Bluetooth</b> speaker"
```

## The Analytics That Actually Matter

Here's where Sarah's original setup really struggled. She needed search results, but also facets for the sidebar: "Show me wireless headphones, but also tell me the price distribution and top brands."

Traditional systems require separate queries. v2 does it in one shot:

```sql
SELECT 
    name, price, rating,
    pdb.agg('{"value_count": {"field": "id"}}') OVER () AS total_results,
    pdb.agg('{"terms": {"field": "category"}}') OVER () AS categories,
    pdb.agg('{"avg": {"field": "rating"}}') OVER () AS avg_rating
FROM products
WHERE description ||| 'wireless'
ORDER BY rating DESC
LIMIT 10;
```

One query returns the top 10 products plus comprehensive analytics. No multiple round-trips, no complex caching strategies.

Want more sophisticated analytics? v2 delivers:

```sql
-- Price distribution in buckets
SELECT pdb.agg('{"range": {"field": "price", "ranges": [
    {"to": 25}, 
    {"from": 25, "to": 100}, 
    {"from": 100}
]}}') FROM products WHERE description ||| 'headphones';

-- Top 3 products in each rating category
SELECT rating, pdb.agg('{"top_hits": {
    "size": 3,
    "sort": [{"created_at": "desc"}],
    "docvalue_fields": ["name", "price"]
}}') FROM products
WHERE description ||| 'wireless'
GROUP BY rating;
```

## Handling the Edge Cases

Every real application hits edge cases. International customers with accented characters. Product descriptions in multiple languages. Complex JSON metadata.

v2 anticipates these scenarios:

```sql
-- International text with the ICU tokenizer
CREATE INDEX products_intl ON products
USING bm25 (id, (description::pdb.icu))
WITH (key_field='id');

SELECT 'Café München'::pdb.icu::text[];
-- Result: {café,münchen}

-- JSON metadata that gets automatically indexed
ALTER TABLE products ADD COLUMN specs JSONB;
CREATE INDEX products_specs ON products  
USING bm25 (id, specs) WITH (key_field='id');

-- Query nested JSON properties
SELECT name FROM products 
WHERE specs @@@ pdb.term_set(['USB-C', 'Lightning']);

-- Aggregate on JSON properties
SELECT pdb.agg('{"terms": {"field": "specs.color"}}')
FROM products WHERE id @@@ pdb.all();
```

## When Search Meets Real Users

The moment of truth: real users doing real searches on real data. Sarah's customers search for everything from specific model numbers to vague descriptions like "good headphones."

v2's query parser handles the complexity:

```sql
-- Let users search like they would in Google
SELECT name, rating FROM products
WHERE id @@@ pdb.parse('description:(wireless OR bluetooth) AND rating:>4', 
                       lenient => true);

-- Handle typos gracefully  
SELECT name FROM products
WHERE description @@@ pdb.fuzzy('wirless hedphones', 2);

-- Power users can use regex
SELECT name FROM products
WHERE name @@@ pdb.regex('iPhone.*Pro');
```

The beauty is that these aren't different systems. It's all SQL, all in your database, all ACID-compliant.

## Performance That Actually Scales

As Sarah's catalog grew from thousands to millions of products, her original search setup started creaking. Full-text scans were slow, and the Elasticsearch cluster was expensive to scale.

v2's Top-N optimization changes the game:

```sql
-- Efficiently finds the best 20 results from millions of products
SELECT name, rating, price FROM products
WHERE description ||| 'smartphone'
ORDER BY rating DESC, price ASC  -- Tiebreaker for stable sorting
LIMIT 20;
```

Under the hood, ParadeDB doesn't scan millions of results then sort them. It uses the index to find the top 20 directly. For large catalogs, this is the difference between sub-second and multi-second queries.

## Growing Beyond Simple Search

Six months into using v2, Sarah's team started getting creative. They wanted "More Like This" recommendations:

```sql
SELECT name FROM products
WHERE description @@@ pdb.more_like_this('
    Wireless noise-cancelling over-ear headphones with premium drivers
');
```

They needed complex boolean queries for advanced filters:

```sql
SELECT name FROM products
WHERE id @@@ pdb.parse('
    (category:headphones OR category:earbuds) AND 
    (specs.wireless:true) AND 
    (rating:>4) AND NOT (name:beats)
');
```

They wanted to highlight search terms in multiple languages:

```sql
SELECT name, pdb.snippets(description, 
    start_tag => '<mark>', 
    end_tag => '</mark>',
    max_num_chars => 100
) FROM products
WHERE description @@@ pdb.phrase('noise cancelling')
LIMIT 5;
```

Every new requirement was just more SQL. No new services, no data pipelines, no operational complexity.

## The Moment It Clicks

The real "aha" moment came when Sarah's team needed to update their search configuration. In the old world, this meant:
1. Update Elasticsearch mappings
2. Reindex everything (hours of downtime)  
3. Update the sync pipeline
4. Deploy application changes
5. Hope nothing broke

With v2, it's just:

```sql
-- Change tokenization strategy
ALTER INDEX products_search SET (description::pdb.simple('stemmer=english'));

-- Reindex concurrently (no downtime)
REINDEX INDEX CONCURRENTLY products_search;
```

The search configuration lives with your schema. Database migrations handle search changes. Everything stays in sync automatically.

## Why This Changes Everything

After using v2 for a year, Sarah reflected on what made the difference. It wasn't any single feature — it was the philosophy. Instead of treating search as a separate concern requiring separate tools, v2 made search feel like a natural extension of SQL.

Her team could:
- **Prototype rapidly** by testing tokenization in SQL
- **Deploy confidently** because search behavior was explicit and testable  
- **Scale efficiently** with Top-N optimization and columnar aggregations
- **Maintain easily** because everything was just PostgreSQL

No more late-night pages about Elasticsearch cluster issues. No more data sync bugs. No more choosing between search functionality and operational simplicity.

The v2 API doesn't just provide search features — it provides a fundamentally different way of thinking about search. One where search feels like it belongs in your database because it actually does.

## Try It Yourself

Ready to experience this for yourself? [Get started with ParadeDB](https://docs.paradedb.com/documentation/getting-started/quickstart) and discover what happens when search stops being a separate system and becomes a natural part of PostgreSQL.

The v2 API is actively evolving, with new features shipping regularly. Your feedback helps shape how search should work in the SQL world. Join the conversation and help us build the future of search databases.