If you’ve ever looked at your search results and wondered, *“why did this come up first?”,* the answer is usually BM25.

> BM25 (short for Best Matching 25, sometimes called Okapi BM25) is a ranking algorithm that scores documents by relevance. It’s a bag-of-words model: it doesn’t care about word order, only about which words appear, how often, and how rare they are.
> 

That’s it. Three simple factors. And yet this decades-old algorithm remains the **baseline for relevance** in modern search. Even the newest retrieval methods, from neural rerankers to vector embeddings, still benchmark themselves against BM25. If your ranking can’t beat BM25 (and you probably can’t), you probably should just join it.

## What is BM25 in Search?

BM25 is a **ranking function.** Given a query and a set of documents, it assigns each document a score that represents “relevance.” Sort by score, and you get an ordering of results that feels useful.

This is what separates search from `grep` or other brute force search tools. `grep` just tells you “the word exists in these documents.” BM25 tells you “this document is more relevant than that one.” It transforms matching into ranking.

The way it does this is fairly straightforward:

- Documents that mention your query terms more often score higher.
- Documents that use *rare* terms get boosted more than those that only use common ones.
- Shorter, more focused documents are preferred over longer ones that only mention the query in passing.

Those three signals — frequency, rarity, and length — are the foundation of BM25.

## History of BM25 (Okapi BM25 Origins)

BM25 wasn’t invented at Google or by a modern startup. It came out of the library sciences.

In the 1980s and 1990s, researchers at City University in London were working on the **Okapi information retrieval system**. The dominant method at the time, TF-IDF, consistently favored long documents. A 10,000-word encyclopedia entry could outrank a concise article that was actually more relevant, simply because it had more words to work with.

Stephen Robertson and Karen Spärck Jones introduced a new family of “Best Matching” formulas to fix the problem. BM25 was the 25th tweak in that series. The number itself means nothing, it just happened to be the version that worked best. But the name stuck, and over time it became the standard.

Today, BM25 is everywhere: Elasticsearch, Solr, OpenSearch, Lucene, Postgres with pg_search, academic databases. It’s the invisible baseline of search. It’s even implemented in most of the vector databases (like Pinecone and Qdrant) because it turns out semantic search doesn’t shine unless you pair with with good old lexical search.

## How BM25 Works (the Formula Explained)

Here’s the (somewhat daunting looking) BM25 formula in its standard form:

$$
⁍
$$

Breaking it down:

- `f(t, D)`: how many times the term *t* appears in document *D* (term frequency).
- `IDF(t)`: how rare the term is across all documents (inverse document frequency).
- `|D|`: document length.
- `avgdl`: average document length across the whole collection.
- `k`, `b`: tunable parameters.

The math says:

- More mentions → higher score.
- Rarer terms → higher score.
- Shorter docs → higher score.

But it also says: *there’s a curve*. Seeing a word 10 times is better than once, but 100 times isn’t much better than 10. BM25 builds in diminishing returns, which is why it feels “natural.”

## Parameters: Tuning `k` and `b`

BM25 isn’t completely fixed — you can tune it.

- **`k` (term frequency saturation):** controls how fast you hit diminishing returns. At low `k`, extra mentions of a term quickly stop adding value. At higher `k`, frequency matters more. Default is usually ~1.2.
- **`b` (length normalization):** controls how much document length affects scoring. At `b = 0`, length doesn’t matter; at `b = 1`, length normalization is fully applied. Default is usually ~0.75.

For most cases, the defaults work fine. But in practice, tweaking `k` and `b` can improve results depending on your dataset.

- If your documents are very short (e.g., tweets), you might lower `b`.
- If your documents are long (e.g., research articles), you might increase it.
- If term frequency is particularly important (e.g., product reviews), raising `k` helps.

This flexibility is part of why BM25 has lasted so long.

## Worked Example: Why BM25 Prefers the Focused Doc

Let’s compare two documents against the query `"inverted index"`.

- **Doc A**: 50 words, mentions “inverted” once and “index” twice.
- **Doc B**: 200 words, mentions “inverted” once and “index” ten times.
- Average document length = 100 words.
- Assume “inverted” is rare (IDF = 2.0), “index” is common (IDF = 1.0).

**Result:**

- Doc A scores higher (**≈4.1**)
- Doc B scores lower (**≈3.2**)

Even though Doc B repeats “index” more, BM25 prefers Doc A because it’s shorter, more focused, and makes better use of the rare term. 

It’s still very important to remember that BM25 has no knowledge of where the words occur in in the text, it evaluates the tokens as a bag of words with no ordering.

## BM25 vs TF-IDF

Before BM25, TF-IDF was the standard. It combined frequency and rarity, but it ignored length. Long documents always had the advantage.

BM25 fixed this by introducing length normalization and tunable parameters. That made it practical for real systems.

| Metric | Keyword Match | TF-IDF | BM25 |
| --- | --- | --- | --- |
| Considers word rarity | ❌ | ✅ | ✅ |
| Considers word frequency | ❌ | ✅ | ✅ |
| Considers document length | ❌ | ❌ | ✅ |
| Tunable parameters | ❌ | ❌ | ✅ |
| Result quality | Low | Medium | High |

Think of BM25 as TF-IDF, but production-ready.

## Variants of BM25

Over time, BM25 inspired variants:

- **BM25F**: lets you weight different fields differently. A match in the title can count more than the same word in the body.
- **BM25+**: adjusts the formula to avoid edge cases where very short documents could get weird scores.

Most systems don’t bother with variants, plain BM25 works well enough that it remains the default.

## BM25 vs Newer Methods

So if BM25 is decades old, why hasn’t it been replaced?

The short answer: **it works, and we don’t have anything better**.

Even today, when neural retrieval and vector embeddings dominate the hype cycle, BM25 still serves as the baseline. Academic papers benchmark against it. Production systems often use it in hybrid search (combining BM25 with vector similarity). And in most cases, BM25 alone still beats embedding search.

BM25’s advantages:

- It’s simple to implement.
- It’s explainable. You can look at the math and understand why a document ranked where it did.
- It’s fast and resource-efficient compared to other models.

## Where BM25 Is Used

You don’t have to be a search engineer to benefit from BM25. It shows up in places you use every day:

- **Academic search**: rare terms bubble up focused papers over general surveys.
- **E-commerce**: “bolster pillow” → BM25 knows “bolster” matters more than “pillow.”
- **Internal search**: tickets, logs, docs, even code search. BM25 keeps results usable instead of noisy.

Without BM25 your search experience quickly devolves into chaos: a pile of matches with no useful order.

## BM25: The Standard for Relevance

BM25 isn’t just a piece of search history. It’s the **minimum viable relevance** in modern search.

It solved TF-IDF’s weaknesses, became the default for most engines, and set the standard every new retrieval method has to beat.

For developers, BM25 is more than trivia. It’s the baseline. Once you understand BM25, you understand the foundation on which modern search is built.
